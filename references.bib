
@article{tootell_functional_1995,
	title = {Functional analysis of human {MT} and related visual cortical areas using magnetic resonance imaging},
	volume = {15},
	issn = {0270-6474},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6577785/},
	doi = {10.1523/JNEUROSCI.15-04-03215.1995},
	abstract = {Using noninvasive functional magnetic resonance imaging (fMRI) technique, we analyzed the responses in human area MT with regard to visual motion, color, and luminance contrast sensitivity, and retinotopy. As in previous PET studies, we found that area MT responded selectively to moving (compared to stationary) stimuli. The location of human MT in the present fMRI results is consistent with that of MT in earlier PET and anatomical studies. In addition we found that area MT has a much higher contrast sensitivity than that in several other areas, including primary visual cortex (V1). Functional MRI half- amplitudes in V1 and MT occurred at approximately 15\% and 1\% luminance contrast, respectively. High sensitivity to contrast and motion in MT have been closely associated with magnocellular stream specialization in nonhuman primates. Human psychophysics indicates that visual motion appears to diminish when moving color-varying stimuli are equated in luminance. Electrophysiological results from macaque MT suggest that the human percept could be due to decreases in firing of area MT cells at equiluminance. We show here that fMRI activity in human MT does in fact decrease at and near individually measured equiluminance. Tests with visuotopically restricted stimuli in each hemifield produced spatial variations in fMRI activity consistent with retinotopy in human homologs of macaque areas V1, V2, V3, and VP. Such activity in area MT appeared much less retinotopic, as in macaque. However, it was possible to measure the interhemispheric spread of fMRI activity in human MT (half amplitude activation across the vertical meridian = approximately 15 degrees).},
	number = {4},
	urldate = {2022-11-22},
	journal = {The Journal of Neuroscience},
	author = {Tootell, RB and Reppas, JB and Kwong, KK and Malach, R and Born, RT and Brady, TJ and Rosen, BR and Belliveau, JW},
	month = apr,
	year = {1995},
	pmid = {7722658},
	pmcid = {PMC6577785},
	pages = {3215--3230},
	file = {PubMed Central Full Text PDF:/home/candemircan/Zotero/storage/7YQHV7EX/Tootell et al. - 1995 - Functional analysis of human MT and related visual.pdf:application/pdf},
}

@article{tootell_functional_1997,
	title = {Functional {Analysis} of {V3A} and {Related} {Areas} in {Human} {Visual} {Cortex}},
	volume = {17},
	url = {http://www.jneurosci.org/content/17/18/7060.abstract},
	doi = {10.1523/JNEUROSCI.17-18-07060.1997},
	abstract = {Using functional magnetic resonance imaging (fMRI) and cortical unfolding techniques, we analyzed the retinotopy, motion sensitivity, and functional organization of human area V3A. These data were compared with data from additional human cortical visual areas, including V1, V2, V3/VP, V4v, and MT (V5). Human V3A has a retinotopy that is similar to that reported previously in macaque: (1) it has a distinctive, continuous map of the contralateral hemifield immediately anterior to area V3, including a unique retinotopic representation of the upper visual field in superior occipital cortex; (2) in some cases the V3A foveal representation is displaced from and superior to the confluent foveal representations of V1, V2, V3, and VP; and (3) inferred receptive fields are significantly larger in human V3A, compared with those in more posterior areas such as V1. However, in other aspects human V3A appears quite different from its macaque counterpart: human V3A is relatively motion-selective, whereas human V3 is less so. In macaque, the situation is qualitatively reversed: V3 is reported to be prominently motion-selective, whereas V3A is less so. As in human and macaque MT, the contrast sensitivity appears quite high in human areas V3 and V3A.},
	number = {18},
	journal = {The Journal of Neuroscience},
	author = {Tootell, Roger B. H. and Mendola, Janine D. and Hadjikhani, Nouchine K. and Ledden, Patrick J. and Liu, Arthur. K. and Reppas, John B. and Sereno, Martin I. and Dale, Anders M.},
	month = sep,
	year = {1997},
	pages = {7060},
}

@article{livingstone_segregation_1988,
	title = {Segregation of form, color, movement, and depth: anatomy, physiology, and perception},
	volume = {240},
	issn = {0036-8075},
	shorttitle = {Segregation of form, color, movement, and depth},
	doi = {10.1126/science.3283936},
	abstract = {Anatomical and physiological observations in monkeys indicate that the primate visual system consists of several separate and independent subdivisions that analyze different aspects of the same retinal image: cells in cortical visual areas 1 and 2 and higher visual areas are segregated into three interdigitating subdivisions that differ in their selectivity for color, stereopsis, movement, and orientation. The pathways selective for form and color seem to be derived mainly from the parvocellular geniculate subdivisions, the depth- and movement-selective components from the magnocellular. At lower levels, in the retina and in the geniculate, cells in these two subdivisions differ in their color selectivity, contrast sensitivity, temporal properties, and spatial resolution. These major differences in the properties of cells at lower levels in each of the subdivisions led to the prediction that different visual functions, such as color, depth, movement, and form perception, should exhibit corresponding differences. Human perceptual experiments are remarkably consistent with these predictions. Moreover, perceptual experiments can be designed to ask which subdivisions of the system are responsible for particular visual abilities, such as figure/ground discrimination or perception of depth from perspective or relative movement--functions that might be difficult to deduce from single-cell response properties.},
	language = {eng},
	number = {4853},
	journal = {Science (New York, N.Y.)},
	author = {Livingstone, M. and Hubel, D.},
	month = may,
	year = {1988},
	pmid = {3283936},
	keywords = {Humans, Animals, Motion Perception, Color Perception, Depth Perception, Form Perception, Visual Pathways, Visual Perception},
	pages = {740--749},
}

@article{kamitani_decoding_2006,
	title = {Decoding {Seen} and {Attended} {Motion} {Directions} from {Activity} in the {Human} {Visual} {Cortex}},
	volume = {16},
	issn = {0960-9822},
	url = {https://www.sciencedirect.com/science/article/pii/S0960982206014643},
	doi = {10.1016/j.cub.2006.04.003},
	abstract = {Functional neuroimaging has successfully identified brain areas that show greater responses to visual motion 1, 2, 3 and adapted responses to repeated motion directions 4, 5, 6. However, such methods have been thought to lack the sensitivity and spatial resolution to isolate direction-selective responses to individual motion stimuli. Here, we used functional magnetic resonance imaging (fMRI) and pattern classification methods 7, 8, 9, 10 to show that ensemble activity patterns in human visual cortex contain robust direction-selective information, from which it is possible to decode seen and attended motion directions. Ensemble activity in areas V1–V4 and MT+/V5 allowed us to decode which of eight possible motion directions the subject was viewing on individual stimulus blocks. Moreover, ensemble activity evoked by single motion directions could effectively predict which of two overlapping motion directions was the focus of the subject's attention and presumably dominant in perception. Our results indicate that feature-based attention can bias direction-selective population activity in multiple visual areas, including MT+/V5 and early visual areas (V1–V4), consistent with gain-modulation models of feature-based attention and theories of early attentional selection. Our approach for measuring ensemble direction selectivity may provide new opportunities to investigate relationships between attentional selection, conscious perception, and direction-selective responses in the human brain.},
	language = {en},
	number = {11},
	urldate = {2022-11-22},
	journal = {Current Biology},
	author = {Kamitani, Yukiyasu and Tong, Frank},
	month = jun,
	year = {2006},
	keywords = {SYSNEURO},
	pages = {1096--1102},
	file = {ScienceDirect Full Text PDF:/home/candemircan/Zotero/storage/74DAVYTR/Kamitani and Tong - 2006 - Decoding Seen and Attended Motion Directions from .pdf:application/pdf;ScienceDirect Snapshot:/home/candemircan/Zotero/storage/R9BLYDV3/S0960982206014643.html:text/html},
}

@article{kourtzi_activation_2000,
	title = {Activation in human {MT}/{MST} by static images with implied motion},
	volume = {12},
	issn = {0898-929X},
	doi = {10.1162/08989290051137594},
	abstract = {A still photograph of an object in motion may convey dynamic information about the position of the object immediately before and after the photograph was taken (implied motion). Medial temporal/medial superior temporal cortex (MT/MST) is one of the main brain regions engaged in the perceptual analysis of visual motion. In two experiments we examined whether MT/MST is also involved in representing implied motion from static images. We found stronger functional magnetic resonance imaging (fMRI) activation within MT/MST during viewing of static photographs with implied motion compared to viewing of photographs without implied motion. These results suggest that brain regions involved in the visual analysis of motion are also engaged in processing implied dynamic information from static images.},
	language = {eng},
	number = {1},
	journal = {Journal of Cognitive Neuroscience},
	author = {Kourtzi, Z. and Kanwisher, N.},
	month = jan,
	year = {2000},
	pmid = {10769305},
	keywords = {Humans, Magnetic Resonance Imaging, Cognition, Motion Perception, Photic Stimulation, Temporal Lobe},
	pages = {48--55},
	file = {Full Text:/home/candemircan/Zotero/storage/XBZKHKCM/Kourtzi and Kanwisher - 2000 - Activation in human MTMST by static images with i.pdf:application/pdf},
}

@article{krekelberg_neural_2003,
	title = {Neural correlates of implied motion},
	volume = {424},
	copyright = {2003 Macmillan Magazines Ltd.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature01852},
	doi = {10.1038/nature01852},
	abstract = {Current views of the visual system assume that the primate brain analyses form and motion along largely independent pathways1; they provide no insight into why form is sometimes interpreted as motion. In a series of psychophysical and electrophysiological experiments in humans and macaques, here we show that some form information is processed in the prototypical motion areas of the superior temporal sulcus (STS). First, we show that STS cells respond to dynamic Glass patterns2, which contain no coherent motion but suggest a path of motion3. Second, we show that when motion signals conflict with form signals suggesting a different path of motion, both humans and monkeys perceive motion in a compromised direction. This compromise also has a correlate in the responses of STS cells, which alter their direction preferences in the presence of conflicting implied motion information. We conclude that cells in the prototypical motion areas in the dorsal visual cortex process form that implies motion. Estimating motion by combining motion cues with form cues may be a strategy to deal with the complexities of motion perception in our natural environment.},
	language = {en},
	number = {6949},
	urldate = {2022-11-22},
	journal = {Nature},
	author = {Krekelberg, Bart and Dannenberg, Sabine and Hoffmann, Klaus-Peter and Bremmer, Frank and Ross, John},
	month = aug,
	year = {2003},
	note = {Number: 6949
Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, multidisciplinary, Science},
	pages = {674--677},
	file = {Full Text PDF:/home/candemircan/Zotero/storage/CCVIN672/Krekelberg et al. - 2003 - Neural correlates of implied motion.pdf:application/pdf;Snapshot:/home/candemircan/Zotero/storage/J93D22BS/nature01852.html:text/html},
}

@article{kim_brain_2007,
	title = {Brain activity accompanying perception of implied motion in abstract paintings},
	volume = {20},
	issn = {0169-1015},
	doi = {10.1163/156856807782758395},
	abstract = {Early 20th century artists including Duchamp and Balla tried to portray moving objects on a static canvas by superimposing objects in successive portrayals of an action. We investigated whether implied motion in those paintings is associated with activation of motion-sensitive area MT+. In Experiment 1, we found that observers rated these kinds of paintings higher in portraying motion than they did other abstract paintings in which motion is not intended. We also found that observers who had previously experienced abstract paintings with implied motion tended to give higher motion ratings to that class of paintings. In Experiment 2, we used functional magnetic resonance imaging (fMRI) to measure brain activity of observers while viewing abstract paintings receiving the highest and the lowest motion rating scores in Experiment 1. We found MT+, but not primary visual cortex (V1), showed greater BOLD responses to abstract paintings with implied motion than to abstract paintings with little motion impression, but only in observers with prior experience viewing those kinds of paintings. These results imply that the neural machinery ordinarily engaged during perception of real visual motion is activated when people view paintings explicitly designed to convey a sense of visual motion. Experience, however, is necessary to achieve this sense of motion.},
	language = {eng},
	number = {6},
	journal = {Spatial Vision},
	author = {Kim, Chai-Youn and Blake, Randolph},
	year = {2007},
	pmid = {18338460},
	keywords = {Brain, Female, Humans, Magnetic Resonance Imaging, Male, Cognition, Motion Perception, Photic Stimulation, Temporal Lobe, Paintings},
	pages = {545--560},
}

@article{senior_functional_2000,
	title = {The functional neuroanatomy of implicit-motion perception or ‘representational momentum’},
	volume = {10},
	issn = {0960-9822},
	url = {https://www.sciencedirect.com/science/article/pii/S0960982299002596},
	doi = {10.1016/S0960-9822(99)00259-6},
	abstract = {Background: When we view static scenes that imply motion — such as an object dropping off a shelf– recognition memory for the position of the object is extrapolated forward. It is as if the object in our mind’s eye comes alive and continues on its course. This phenomenon is known as representational momentum and results in a distortion of recognition memory in the implied direction of motion. Representational momentum is modifiable; simply labelling a drawing of a pointed object as ‘rocket’ will facilitate the effect, whereas the label ‘steeple’ will impede it. We used functional magnetic resonance imaging (fMRI) to explore the neural substrate for representational momentum. Results: Subjects participated in two experiments. In the first, they were presented with video excerpts of objects in motion (versus the same objects in a resting position). This identified brain areas responsible for motion perception. In the second experiment, they were presented with still photographs of the same target items, only some of which implied motion (representational momentum stimuli). When viewing still photographs of scenes implying motion, activity was revealed in secondary visual cortical regions that overlap with areas responsible for the perception of actual motion. Additional bilateral activity was revealed within a posterior satellite of V5 for the representational momentum stimuli. Activation was also engendered in the anterior cingulate cortex. Conclusions: Considering the implicit nature of representational momentum and its modifiability, the findings suggest that higher-order semantic information can act on secondary visual cortex to alter perception without explicit awareness.},
	language = {en},
	number = {1},
	urldate = {2022-11-22},
	journal = {Current Biology},
	author = {Senior, C. and Barnes, J. and Giampietroc, V. and Simmons, A. and Bullmore, E. T. and Brammer, M. and David, A. S.},
	month = jan,
	year = {2000},
	pages = {16--22},
	file = {ScienceDirect Full Text PDF:/home/candemircan/Zotero/storage/9ZBVARNB/Senior et al. - 2000 - The functional neuroanatomy of implicit-motion per.pdf:application/pdf;ScienceDirect Snapshot:/home/candemircan/Zotero/storage/L9U9DRN8/S0960982299002596.html:text/html},
}

@article{bremmer_polymodal_2001,
	title = {Polymodal {Motion} {Processing} in {Posterior} {Parietal} and {Premotor} {Cortex}: {A} {Human} {fMRI} {Study} {Strongly} {Implies} {Equivalencies} between {Humans} and {Monkeys}},
	volume = {29},
	issn = {0896-6273},
	shorttitle = {Polymodal {Motion} {Processing} in {Posterior} {Parietal} and {Premotor} {Cortex}},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627301001982},
	doi = {10.1016/S0896-6273(01)00198-2},
	abstract = {In monkeys, posterior parietal and premotor cortex play an important integrative role in polymodal motion processing. In contrast, our understanding of the convergence of senses in humans is only at its beginning. To test for equivalencies between macaque and human polymodal motion processing, we used functional MRI in normals while presenting moving visual, tactile, or auditory stimuli. Increased neural activity evoked by all three stimulus modalities was found in the depth of the intraparietal sulcus (IPS), ventral premotor, and lateral inferior postcentral cortex. The observed activations strongly suggest that polymodal motion processing in humans and monkeys is supported by equivalent areas. The activations in the depth of IPS imply that this area constitutes the human equivalent of macaque area VIP.},
	language = {en},
	number = {1},
	urldate = {2022-11-22},
	journal = {Neuron},
	author = {Bremmer, Frank and Schlack, Anja and Shah, N. Jon and Zafiris, Oliver and Kubischik, Michael and Hoffmann, Klaus-Peter and Zilles, Karl and Fink, Gereon R.},
	month = jan,
	year = {2001},
	pages = {287--296},
	file = {ScienceDirect Full Text PDF:/home/candemircan/Zotero/storage/F5EE8XE4/Bremmer et al. - 2001 - Polymodal Motion Processing in Posterior Parietal .pdf:application/pdf;ScienceDirect Snapshot:/home/candemircan/Zotero/storage/2ZVVHQ73/S0896627301001982.html:text/html},
}
